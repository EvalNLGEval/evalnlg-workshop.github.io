---
title: "Accepted Papers"
permalink: /accepted-papers/
layout: single
classes: wide
header:
  overlay_color: "#000"
  overlay_filter: "0.1"
  overlay_image: /assets/images/bc.png
---

## Abstracts

* Evaluating AMR-to-English NLG Evaluation 
<br />
Emma Manning, Shira Wein and Nathan Schneider

* Informative Manual Evaluation of Machine Translation Output 
<br />
Maja Popovic

* Automatic Machine Translation Evaluation in Many Languages via Zero-Shot Paraphrasing
<br />
Brian Thompson and Matt Post

* Evaluating Semantic Accuracy of Data-to-Text Generation with Natural Language Inference
<br />
Ondrej Dusek and Zdenek Kasner

* Studying the Effects of Cognitive Biases in Evaluation of Conversational Agents
<br />
Sashank Santhanam and Samira Shaikh


## Archival

* A proof of concept on triangular test evaluation for Natural Language Generation
<br />
Javier González Corbelle, José María Alonso Moral and Alberto Bugarín Diz

* This is a Problem, Don't You Agree? Framing and Bias in Human Evaluation for Natural Language Generation
<br />
Stephanie Schoch, Diyi Yang and Yangfeng Ji

* NUBIA: NeUral Based Interchangeability Assessor for Text Generation
<br />
Hassan Kane, Muhammed Yusuf Kocyigit, Ali Abdalla, Pelkins Ajanoh and Mohamed Coulibali

* On the interaction of automatic evaluation and task framing in headline style transfer
<br />
Lorenzo De Mattei, Michele Cafagna, Huiyuan Lai, Felice Dell'Orletta, Malvina Nissim and Albert Gatt

* Evaluation rules! On the use of grammars and rule-based systems for NLG evaluation
<br />
Emiel van Miltenburg, Chris van der Lee, Thiago Castro-Ferreira and Emiel Krahmer